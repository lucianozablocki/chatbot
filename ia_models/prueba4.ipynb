{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prueba4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYWDo-0OrddA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch as tr\n",
        "#import numpy as np\n",
        "import pandas\n",
        "#CHAR_CHANNELS = 55\n",
        "\n",
        "class CharTokenizer():\n",
        "    def __init__(self):\n",
        "        #emb = np.eye(80, 55)\n",
        "        #emb[54:80] = emb[28:54]\n",
        "        #emb[28:54, 54] = 1\n",
        "        emb = tr.eye(80,80)\n",
        "        self.embedding = emb\n",
        "\n",
        "    def tokenize(self, comments): #comments es lista de palabras\n",
        "        return list(map(lambda x:self.str2tns(x), comments)) #x->a cada elemento de comments\n",
        "                                                            #(palabra) le aplico str2tns\n",
        "\n",
        "    def str2tns(self, comm): #comm es una palabra\n",
        "        return tr.LongTensor(list(map(self.char2idx, comm))) #a cada elemento de la palabra \n",
        "                                                #(caracter) le aplico char2idx\n",
        "\n",
        "    def char2idx(self, c): #c es un caracter\n",
        "        idx = 27     \n",
        "        #print(c)\n",
        "        if c in self.char_set:\n",
        "            idx = self.char_set[c]\n",
        "        return idx\n",
        "    \n",
        "    #def get_tensor(self,idx):\n",
        "    #    return list(map(lambda x: self.embedding[x],idx))\n",
        "\n",
        "    char_set = {\n",
        "            ' ' : 0, '\\n': 1, '!' :  2, '\"' :  3, '#' :  4, '$' :  5, '%' :  6, '&' :  7, \"'\" :  8,\n",
        "            '(' :  9, ')' : 10, '*' : 11, '+' : 12, ',' : 13, '-' : 14, '.' : 15, '/' : 16, ':' : 17,\n",
        "            ';' : 18, '=' : 19, '?' : 20, '_' : 21, '\\xad' : 22, '’' : 23, '“' : 24, '”' : 25,\n",
        "            '0' : 26, '1' : 26, '2' : 26, '3' : 26, '4' : 26, '5' : 26, '6' : 26, '7' : 26, '8' : 26,\n",
        "            '9' : 26,\n",
        "            'A' : 28, 'B' : 29, 'C' : 30, 'D' : 31, 'E' : 32, 'F' : 33, 'G' : 34, 'H' : 35, 'I' : 36,\n",
        "            'J' : 37, 'K' : 38, 'L' : 39, 'M' : 40, 'N' : 41, 'O' : 42, 'P' : 43, 'Q' : 44, 'R' : 45,\n",
        "            'S' : 46, 'T' : 47, 'U' : 48, 'V' : 49, 'W' : 50, 'X' : 51, 'Y' : 52, 'Z' : 53,\n",
        "            'a' : 28, 'b' : 29, 'c' : 30, 'd' : 31, 'e' : 32, 'f' : 33, 'g' : 34, 'h' : 35, 'i' : 36,\n",
        "            'j' : 37, 'k' : 38, 'l' : 39, 'm' : 40, 'n' : 41, 'o' : 42, 'p' : 43, 'q' : 44, 'r' : 45,\n",
        "            's' : 46, 't' : 47, 'u' : 48, 'v' : 49, 'w' : 50, 'x' : 51, 'y' : 52, 'z' : 53}\n",
        "    \"\"\"\n",
        "    char_set={'a':0,'b':1,'c':2}\n",
        "    \"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNQKs9YFD10a",
        "colab_type": "code",
        "outputId": "99de887e-4f7c-4fe5-dd16-9b3ea6de5ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXflzMA-q8-i",
        "colab_type": "code",
        "outputId": "95c3dedf-9a7f-4fde-cec3-2a46f4eae16b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "import torch as torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import pandas as pn\n",
        "#from char_tokenizer import CharTokenizer\n",
        "#import utils\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "import torch.nn.functional as F\n",
        "#from utils import EarlyStopping\n",
        "from matplotlib import pyplot as plt\n",
        "!pip install skorch\n",
        "import skorch\n",
        "from skorch import NeuralNetClassifier,NeuralNet\n",
        "from sklearn.model_selection import RandomizedSearchCV,train_test_split,GridSearchCV\n",
        "from mpl_toolkits import mplot3d\n",
        "import scipy.interpolate as interp\n",
        "from mpl_toolkits.mplot3d import Axes3D\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: skorch in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (4.28.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.3.3)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.8.6)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.17.4)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.21.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (0.14.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsOvS47_r-pH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_encode(indx, dict_size, maxlen, batch_size):\n",
        "    # Creating a multi-dimensional array of zeros with the desired output shape\n",
        "    features = np.zeros((batch_size, maxlen, dict_size), dtype=np.float32)\n",
        "    \n",
        "    # Replacing the 0 at the relevant character index with a 1 to represent that character\n",
        "    for i in range(batch_size):\n",
        "        for u in range(maxlen):\n",
        "            features[i, u, int(indx[i][u])] = 1\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxnIF3r0sJfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size,maxlen,num_layers):\n",
        "        super(CNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        if num_layers == 2:\n",
        "            self.block=nn.Sequential(nn.Conv1d(input_size,hidden_size,3,padding=1),nn.ReLU(),nn.BatchNorm1d(hidden_size),nn.AvgPool1d(2),\n",
        "            nn.Conv1d(hidden_size,hidden_size,3,padding=1),nn.ReLU(),nn.BatchNorm1d(hidden_size),nn.AvgPool1d(2))\n",
        "        elif num_layers == 3:\n",
        "            self.block=nn.Sequential(nn.Conv1d(input_size,hidden_size,3,padding=1),nn.ReLU(),nn.BatchNorm1d(hidden_size),nn.AvgPool1d(2),\n",
        "            nn.Conv1d(hidden_size,hidden_size,3,padding=1),nn.ReLU(),nn.BatchNorm1d(hidden_size),nn.AvgPool1d(2),\n",
        "            nn.Conv1d(hidden_size,hidden_size,3,padding=1),nn.ReLU(),nn.BatchNorm1d(hidden_size),nn.AvgPool1d(2))\n",
        "        elif num_layers == 4:\n",
        "            self.block=nn.Sequential(nn.Conv1d(input_size,hidden_size,3,padding=1),nn.ReLU(),nn.BatchNorm1d(hidden_size),nn.AvgPool1d(2),\n",
        "            nn.Conv1d(hidden_size,hidden_size,3,padding=1),nn.ReLU(),nn.BatchNorm1d(hidden_size),nn.AvgPool1d(2),\n",
        "            nn.Conv1d(hidden_size,hidden_size,3,padding=1),nn.ReLU(),nn.BatchNorm1d(hidden_size),nn.AvgPool1d(2),\n",
        "            nn.Conv1d(hidden_size,hidden_size,3,padding=1),nn.ReLU(),nn.BatchNorm1d(hidden_size),nn.AvgPool1d(2))\n",
        "        self.out = nn.Linear(hidden_size*int(maxlen/2**num_layers),output_size)\n",
        "        \"\"\"        \n",
        "        self.c1 = nn.Conv1d(input_size, hidden_size, 3,padding=1)\n",
        "        self.a1 = nn.ReLU()\n",
        "        self.b1 = nn.BatchNorm1d(hidden_size)\n",
        "        self.p1 = nn.AvgPool1d(2)\n",
        "        \n",
        "        self.c2 = nn.Conv1d(hidden_size, hidden_size, 3,padding=1)\n",
        "        self.a2 = nn.ReLU()\n",
        "        self.b2 = nn.BatchNorm1d(hidden_size)\n",
        "        self.p2 = nn.AvgPool1d(2)\n",
        "        \n",
        "        self.c3 = nn.Conv1d(hidden_size, hidden_size, 3,padding=1)\n",
        "        self.a3 = nn.ReLU()\n",
        "        self.b3 = nn.BatchNorm1d(hidden_size)\n",
        "        self.p3 = nn.AvgPool1d(2)\n",
        "        \n",
        "        #nn.Sequential(nn.Conv1d(input_size,hidden_size,3),\n",
        "        #)\n",
        "        #self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=0.01)\n",
        "        #self.gru = nn.GRU(input_size,hidden_size,n_layers,dropout=0.01)\n",
        "        self.out = nn.Linear(hidden_size*int(maxlen/2**num_layers), output_size)\n",
        "        \"\"\"\n",
        "\n",
        "    def forward(self, inputs, hidden=None):\n",
        "        #batch_size = inputs.size(1)\n",
        "        #batch_size = inputs.size(0)\n",
        "        #print(\"dimensiones del tensor que entra a la cnn: \",inputs.shape)\n",
        "        # Turn (seq_len x batch_size x input_size) into (batch_size x input_size x seq_len) for CNN\n",
        "        #inputs = inputs.transpose(0, 1).transpose(1, 2)\n",
        "\n",
        "        #entra un tensor de dimensiones: batch x seq_len x input_size\n",
        "        #quiero un tensor dedimensiones: batch x input_size x seq_len\n",
        "        inputs = inputs.transpose(1, 2)\n",
        "        x = self.block(inputs)\n",
        "        #print(x.shape)\n",
        "        \"\"\"\n",
        "        # Run through Conv1d and Pool1d layers\n",
        "        c = self.c1(inputs)\n",
        "        #print(\"Paso primera capa\")\n",
        "        #usar relu y batch norm a la salida \n",
        "        a = self.a1(c)\n",
        "        b = self.b1(a)\n",
        "        p = self.p1(b)\n",
        "        #print(\"Paso segunda capa\")\n",
        "        c = self.c2(p)\n",
        "        a = self.a2(c)\n",
        "        b = self.b2(a)\n",
        "        p = self.p2(b)\n",
        "        #print(\"Paso tercera capa\")\n",
        "        #print(\"Paso cuarta capa\")\n",
        "        c = self.c3(p)\n",
        "        a = self.a3(c)\n",
        "        b = self.b3(a)\n",
        "        p = self.p3(b)\n",
        "        #print(\"dimensiones del tensor que sale de la cnn antes de transpose: \",p.shape)\n",
        "        \n",
        "        # Turn (batch_size x hidden_size x seq_len) back into (seq_len x batch_size x hidden_size) for RNN\n",
        "        #p = p.transpose(1, 2).transpose(0, 1)\n",
        "        #print(\"dimensiones del tensor que entra a la gru antes de transpose: \",p.shape)\n",
        "        #sale tensor de batch_size x hidden_size x seq_len\n",
        "        \n",
        "        #quiero tensor de seq_len x batch_size x hidden_size\n",
        "        #p = p.transpose(0,1).transpose(0,2)\n",
        "        #print(\"dimensiones del tensor que entra a la gru dsp de transpose: \",p.shape)\n",
        "        #p = torch.tanh(p)\n",
        "        #output, hidden = self.gru(p, hidden)\n",
        "        #print(\"Paso quinta capa\")\n",
        "        #print(\"dimension de lo que sale de la gru \",output.shape)\n",
        "        \n",
        "        #conv_seq_len = p.shape[2]\n",
        "        #p = p.view(-1,conv_seq_len * self.hidden_size) # Treating (conv_seq_len x batch_size) as batch_size for linear layer\n",
        "        \"\"\"\n",
        "        p = torch.flatten(x,start_dim=1)\n",
        "        #output = torch.tanh(self.out(output))\n",
        "        #output = self.out(output.reshape(-1,conv_seq_len*self.hidden_size))\n",
        "        #output = self.out(output.reshape(conv_seq_len*batch_))\n",
        "        output = self.out(p)\n",
        "        #print(\"Paso ultima capa\")\n",
        "        #print(\"shape de la salida:\",output.shape)\n",
        "        \n",
        "        #output = output.view(conv_seq_len, -1, self.output_size)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BiC5WHgsOYV",
        "colab_type": "code",
        "outputId": "4e97484e-b32e-4d85-8b75-92b00200c1bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "correctedData = pn.read_csv(\"preprocessedQuestions_lem.csv\",delimiter=',',header=None) #comentar esta linea en caso de descomentar la anterior\n",
        "cantidad_preg = correctedData.shape[0]\n",
        "#Xtrain,Ytrain,Xtest,Ytest,Xval,Yval = utils.separate_dataset(correctedData.values,cantidad_preg,True)\n",
        "print(\"llego hasta dsp de separate dataset\")\n",
        "#print(correctedData.values[:,1])\n",
        "text = correctedData.values[:,1]\n",
        "#labels = correctedData.values[:,0]\n",
        "#labels = np.array(labels,dtype=np.int8)\n",
        "# Finding the length of the longest string in our data\n",
        "maxlen = len(max(text, key=len))\n",
        "#print(maxlen)\n",
        "# Padding"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "llego hasta dsp de separate dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdJNmRvosiTb",
        "colab_type": "code",
        "outputId": "e6c1c45b-621f-49c7-b961-32a73107d1e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# A simple loop that loops through the list of sentences and adds a ' ' whitespace until the length of\n",
        "# the sentence matches the length of the longest sentence\n",
        "\n",
        "for i in range(len(text)):\n",
        "    while(len(text[i]))<maxlen:\n",
        "        text[i] += ' '\n",
        "\n",
        "#for i in range(len(Xtrain)):\n",
        "#    while len(Xtrain[i,0])<maxlen:\n",
        "#        Xtrain[i,0] += ' ' \n",
        "\n",
        "#for i in range(len(Xtest)):\n",
        "#    while len(Xtest[i,0])<maxlen:\n",
        "#        Xtest[i,0] += ' '\n",
        "\n",
        "#for i in range(len(Xval)):\n",
        "#    while len(Xval[i,0])<maxlen:\n",
        "#        Xval[i,0] += ' '\n",
        "\n",
        "print(\"llego hasta dsp de llenar con whitespace\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "llego hasta dsp de llenar con whitespace\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40XxPj9KskWz",
        "colab_type": "code",
        "outputId": "982c44ca-f770-400a-efa3-4ee6b164aa2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "char = CharTokenizer()\n",
        "indxChar = np.zeros((len(text),maxlen))\n",
        "#indxTrain= np.zeros((len(Xtrain),maxlen))\n",
        "#indxTest = np.zeros((len(Xtest),maxlen))\n",
        "#indxVal = np.zeros((len(Xval),maxlen))\n",
        "#indx es una matriz que tiene en cada fila los indices de los caracteres de la oracion, y maxlen columnas\n",
        "for i in range(len(text)):\n",
        "    indxChar[i] = char.tokenize(text[i])\n",
        "#for i in range(len(Xtrain)):\n",
        "#    indxTrain[i] = char.tokenize(Xtrain[i,0])\n",
        "#for i in range(len(Xtest)):\n",
        "#    indxTest[i] = char.tokenize(Xtest[i,0])\n",
        "#for i in range(len(Xval)):\n",
        "#    indxVal[i] = char.tokenize(Xval[i,0])\n",
        "#print(indxTest[0])\n",
        "#print(indxTest[60])\n",
        "\n",
        "print(\"llego hasta dsp de char tokenize\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "llego hasta dsp de char tokenize\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL2-IVNqspMU",
        "colab_type": "code",
        "outputId": "87cb6887-58cd-446e-ba9e-3632425e0305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dict_size = len(char.char_set)\n",
        "#dict_size = 80\n",
        "#print(dict_size)\n",
        "#batch_size_train = len(Xtrain)\n",
        "#batch_size_test = len(Xtest)\n",
        "#batch_size_val = len(Xval)\n",
        "#seq_len = maxlen\n",
        "cant_preg = len(text)\n",
        "X = one_hot_encode(indxChar,dict_size,maxlen,cant_preg)\n",
        "Y = [x[0] for x in correctedData.values]\n",
        "#input_seq_train = one_hot_encode(indxTrain,dict_size,maxlen,batch_size_train)\n",
        "#input_seq_test = one_hot_encode(indxTest,dict_size,maxlen,batch_size_test)\n",
        "#input_seq_val = one_hot_encode(indxVal,dict_size,maxlen,batch_size_val)\n",
        "#input_seq_train = torch.from_numpy(input_seq_train)\n",
        "#input_seq_test = torch.from_numpy(input_seq_test)\n",
        "#input_seq_val = torch.from_numpy(input_seq_val)\n",
        "#target_seq_train = Ytrain\n",
        "#target_seq_test = Ytest\n",
        "#target_seq_val = Yval\n",
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")\n",
        "\n",
        "cantidad_labels = correctedData.values[len(correctedData.values)-1,0] + 1\n",
        "# Instantiate the model with hyperparameters\n",
        "#model = sRNN(input_size=dict_size, output_size=cantidad_labels, hidden_dim=12, n_layers=1)\n",
        "#model = sRNN(input_size=dict_size, output_size=cantidad_labels, hidden_dim=20, n_layers=1,bidirectional=True)\n",
        "# Define hyperparameters\n",
        "n_epochs = 500\n",
        "batch_size = 500\n",
        "hidden_size = 20\n",
        "num_layers=3\n",
        "model = CNN(input_size=dict_size,hidden_size = hidden_size,output_size=cantidad_labels,maxlen=maxlen,num_layers=num_layers)\n",
        "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
        "model = model.to(device)\n",
        "\n",
        "parameters = {    \n",
        "    #'module__hidden_dim' : [12,24,48,96],\n",
        "    'module__hidden_size' : [20,50,80,40],    \n",
        "    #'max_epochs' : [50,70,90,110,130,150]\n",
        "    'module__num_layers':[2,3,4],\n",
        "    'max_epochs' : [50,100],\n",
        "    'batch_size' : [1000,500,700,150]\n",
        "}\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON_bkmatki6y",
        "colab_type": "code",
        "outputId": "2bce70db-3eeb-471f-809b-1e695ad064c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "net = NeuralNetClassifier(model,module__input_size = dict_size,module__hidden_size=hidden_size,module__output_size=cantidad_labels,module__maxlen=maxlen,module__num_layers=num_layers,criterion=torch.nn.CrossEntropyLoss,optimizer=torch.optim.Adam,verbose=1,device=device)\n",
        "gs = RandomizedSearchCV(net,parameters,verbose=2,n_jobs=-1,cv=10,scoring='balanced_accuracy',n_iter=2)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,Y,shuffle=True,stratify=Y,test_size=0.1,random_state=12)\n",
        "#y_train_tensor = torch.LongTensor(y_train)\n",
        "#y_test_tensor = torch.LongTensor(y_test)\n",
        "Y_numpy = np.asarray(y_train)\n",
        "\n",
        "gs.fit(X_train,Y_numpy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 9 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
            "  % (min_groups, self.n_splits)), Warning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Re-initializing module because the following parameters were re-set: hidden_size, input_size, maxlen, num_layers, output_size.\n",
            "Re-initializing module because the following parameters were re-set: hidden_size, input_size, maxlen, num_layers, output_size.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m5.0461\u001b[0m       \u001b[32m0.0127\u001b[0m        \u001b[35m4.7539\u001b[0m  0.1155\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  3.0min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "      2        5.2540       0.0063        6.6060  0.1134\n",
            "      3        \u001b[36m4.4194\u001b[0m       0.0095        5.4357  0.1097\n",
            "      4        \u001b[36m3.8710\u001b[0m       0.0063        7.0854  0.1087\n",
            "      5        \u001b[36m3.4435\u001b[0m       \u001b[32m0.0158\u001b[0m        6.6281  0.1119\n",
            "      6        \u001b[36m3.0267\u001b[0m       \u001b[32m0.0253\u001b[0m        5.2838  0.1123\n",
            "      7        \u001b[36m2.6431\u001b[0m       \u001b[32m0.0348\u001b[0m        5.3516  0.1110\n",
            "      8        \u001b[36m2.2461\u001b[0m       \u001b[32m0.0601\u001b[0m        4.9793  0.1211\n",
            "      9        \u001b[36m1.8722\u001b[0m       0.0506        5.8789  0.1138\n",
            "     10        \u001b[36m1.5684\u001b[0m       \u001b[32m0.1297\u001b[0m        \u001b[35m3.7297\u001b[0m  0.1125\n",
            "     11        \u001b[36m1.2836\u001b[0m       0.1171        5.3645  0.1121\n",
            "     12        \u001b[36m1.1266\u001b[0m       \u001b[32m0.2943\u001b[0m        \u001b[35m3.5244\u001b[0m  0.1120\n",
            "     13        \u001b[36m0.9380\u001b[0m       0.2848        3.8615  0.1130\n",
            "     14        \u001b[36m0.6867\u001b[0m       0.2690        4.1197  0.1142\n",
            "     15        \u001b[36m0.4674\u001b[0m       \u001b[32m0.3481\u001b[0m        \u001b[35m3.3362\u001b[0m  0.1134\n",
            "     16        \u001b[36m0.3229\u001b[0m       \u001b[32m0.4557\u001b[0m        \u001b[35m2.9736\u001b[0m  0.1132\n",
            "     17        \u001b[36m0.2173\u001b[0m       0.4304        \u001b[35m2.8854\u001b[0m  0.1174\n",
            "     18        \u001b[36m0.1419\u001b[0m       0.3671        3.3115  0.1121\n",
            "     19        \u001b[36m0.0968\u001b[0m       \u001b[32m0.4715\u001b[0m        \u001b[35m2.7874\u001b[0m  0.1110\n",
            "     20        \u001b[36m0.0695\u001b[0m       \u001b[32m0.4747\u001b[0m        2.8520  0.1110\n",
            "     21        \u001b[36m0.0479\u001b[0m       \u001b[32m0.4842\u001b[0m        2.9113  0.1116\n",
            "     22        \u001b[36m0.0386\u001b[0m       \u001b[32m0.4905\u001b[0m        2.7908  0.1127\n",
            "     23        0.0399       \u001b[32m0.4968\u001b[0m        2.8650  0.1149\n",
            "     24        \u001b[36m0.0317\u001b[0m       0.4367        3.2787  0.1108\n",
            "     25        \u001b[36m0.0316\u001b[0m       0.4399        3.1668  0.1191\n",
            "     26        \u001b[36m0.0231\u001b[0m       0.4335        3.2566  0.1149\n",
            "     27        \u001b[36m0.0220\u001b[0m       0.4873        2.8529  0.1169\n",
            "     28        \u001b[36m0.0183\u001b[0m       0.4968        2.9284  0.1114\n",
            "     29        0.0193       0.4462        3.2319  0.1132\n",
            "     30        0.0184       \u001b[32m0.5032\u001b[0m        2.9066  0.1126\n",
            "     31        0.0196       0.4747        2.9989  0.1121\n",
            "     32        \u001b[36m0.0174\u001b[0m       0.4810        3.1076  0.1127\n",
            "     33        0.0201       0.4937        2.9493  0.1210\n",
            "     34        \u001b[36m0.0173\u001b[0m       \u001b[32m0.5063\u001b[0m        2.9561  0.1112\n",
            "     35        \u001b[36m0.0162\u001b[0m       0.4937        2.9846  0.1115\n",
            "     36        \u001b[36m0.0141\u001b[0m       0.5000        2.9425  0.1122\n",
            "     37        0.0166       0.4968        3.0189  0.1127\n",
            "     38        0.0146       0.5032        2.9523  0.1157\n",
            "     39        0.0143       0.4937        2.9383  0.1125\n",
            "     40        \u001b[36m0.0134\u001b[0m       0.4937        2.9806  0.1147\n",
            "     41        0.0148       0.4968        2.9347  0.1190\n",
            "     42        0.0158       0.4937        3.1723  0.1140\n",
            "     43        0.0162       0.4462        3.2496  0.1235\n",
            "     44        0.0138       0.4430        3.5350  0.1109\n",
            "     45        0.0137       0.5000        3.1082  0.1129\n",
            "     46        0.0222       0.4114        3.4979  0.1123\n",
            "     47        0.0327       0.4146        3.8689  0.1161\n",
            "     48        0.0225       0.3608        4.4905  0.1127\n",
            "     49        0.0197       0.3196        5.4959  0.1137\n",
            "     50        0.0193       0.4684        3.5653  0.1209\n",
            "     51        0.0139       0.4462        3.4213  0.1123\n",
            "     52        \u001b[36m0.0119\u001b[0m       0.4905        3.2472  0.1115\n",
            "     53        0.0162       0.4241        4.0668  0.1117\n",
            "     54        0.0133       0.4652        3.2292  0.1129\n",
            "     55        \u001b[36m0.0109\u001b[0m       0.4652        3.2247  0.1103\n",
            "     56        0.0109       0.4620        3.5078  0.1108\n",
            "     57        0.0125       0.4873        3.1210  0.1137\n",
            "     58        \u001b[36m0.0093\u001b[0m       0.4557        3.3340  0.1147\n",
            "     59        \u001b[36m0.0076\u001b[0m       0.4304        3.9927  0.1092\n",
            "     60        0.0078       0.5000        3.1221  0.1083\n",
            "     61        0.0084       0.4905        3.1550  0.1122\n",
            "     62        0.0076       0.4905        3.1746  0.1109\n",
            "     63        \u001b[36m0.0067\u001b[0m       0.4778        3.2897  0.1115\n",
            "     64        \u001b[36m0.0059\u001b[0m       0.5000        3.1455  0.1099\n",
            "     65        0.0059       0.4937        3.1136  0.1126\n",
            "     66        0.0064       0.5000        3.1814  0.1183\n",
            "     67        0.0067       0.4747        3.2023  0.1086\n",
            "     68        0.0067       0.5000        3.1655  0.1096\n",
            "     69        0.0061       0.5000        3.1334  0.1147\n",
            "     70        \u001b[36m0.0054\u001b[0m       0.4968        3.1891  0.1123\n",
            "     71        \u001b[36m0.0049\u001b[0m       0.4747        3.2276  0.1107\n",
            "     72        \u001b[36m0.0044\u001b[0m       0.4968        3.1735  0.1093\n",
            "     73        \u001b[36m0.0042\u001b[0m       0.4968        3.1676  0.1106\n",
            "     74        \u001b[36m0.0040\u001b[0m       0.4968        3.1912  0.1190\n",
            "     75        \u001b[36m0.0039\u001b[0m       0.4937        3.2058  0.1108\n",
            "     76        \u001b[36m0.0038\u001b[0m       0.4937        3.1992  0.1096\n",
            "     77        0.0044       0.4937        3.2837  0.1133\n",
            "     78        0.0050       0.4873        3.2404  0.1160\n",
            "     79        0.0053       0.4747        3.2802  0.1128\n",
            "     80        0.0061       0.4968        3.1930  0.1122\n",
            "     81        0.0103       0.4620        3.5680  0.1129\n",
            "     82        0.0098       0.4747        3.3559  0.1193\n",
            "     83        0.0081       0.3861        4.7439  0.1148\n",
            "     84        0.0130       0.4241        4.1678  0.1153\n",
            "     85        0.0160       0.2690        5.6463  0.1121\n",
            "     86        0.0158       0.4272        3.8190  0.1104\n",
            "     87        0.0242       0.4430        3.7225  0.1096\n",
            "     88        0.0685       0.2405        8.4354  0.1161\n",
            "     89        0.3456       0.1013       20.3792  0.1118\n",
            "     90        0.6941       0.1203       16.5031  0.1140\n",
            "     91        0.9873       0.0791       30.3575  0.1101\n",
            "     92        0.7302       0.3038        8.1128  0.1115\n",
            "     93        0.4293       0.3196        6.5543  0.1108\n",
            "     94        0.2900       0.3228        6.8233  0.1133\n",
            "     95        0.1409       0.4525        4.1601  0.1097\n",
            "     96        0.0667       0.4873        4.1130  0.1098\n",
            "     97        0.0333       0.4842        3.7238  0.1080\n",
            "     98        0.0176       0.4905        3.5921  0.1101\n",
            "     99        0.0125       0.4905        3.5220  0.1127\n",
            "    100        0.0112       0.4968        3.5002  0.1106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=10, error_score='raise-deprecating',\n",
              "                   estimator=<class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n",
              "  module=CNN(\n",
              "    (block): Sequential(\n",
              "      (0): Conv1d(88, 20, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (1): ReLU()\n",
              "      (2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): AvgPool1d(kernel_size=(2,), stride=(2,),...\n",
              "  module__maxlen=169,\n",
              "  module__num_layers=3,\n",
              "  module__output_size=106,\n",
              "),\n",
              "                   iid='warn', n_iter=2, n_jobs=-1,\n",
              "                   param_distributions={'batch_size': [1000, 500, 700, 150],\n",
              "                                        'max_epochs': [50, 100],\n",
              "                                        'module__hidden_size': [20, 50, 80, 40],\n",
              "                                        'module__num_layers': [2, 3, 4]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring='balanced_accuracy',\n",
              "                   verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlT8llhXkosW",
        "colab_type": "code",
        "outputId": "fdff9f1e-1a2c-4edb-cb3f-08603e9e597b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "hidden_size = []\n",
        "max_epochs = []\n",
        "batch_size = []\n",
        "num_layers = []\n",
        "score = []\n",
        "std=[]\n",
        "\n",
        "# Utility function to report best scores (found online)\n",
        "def report(results, n_top=3):\n",
        "    for i in range(1, n_top + 1):\n",
        "        print(i)\n",
        "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
        "        for candidate in candidates:\n",
        "            print(\"Model with rank: {0}\".format(i))\n",
        "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
        "                  results['mean_test_score'][candidate],\n",
        "                  results['std_test_score'][candidate]))\n",
        "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
        "            print(\"\")\n",
        "            batch_size.append(results['params'][candidate]['batch_size'])\n",
        "            hidden_size.append(results['params'][candidate]['module__hidden_size'])\n",
        "            num_layers.append(results['params'][candidate]['module__num_layers'])\n",
        "            max_epochs.append(results['params'][candidate]['max_epochs'])\n",
        "            score.append(results['mean_test_score'][candidate])\n",
        "            std.append(results['std_test_score'][candidate])\n",
        "report(gs.cv_results_,2)\n",
        "\n",
        "\n",
        "print(\"Batch size: \",batch_size)\n",
        "print(\"Hidden Dim: \",hidden_size)\n",
        "print(\"Max epochs: \",max_epochs)\n",
        "print(\"Num layers: \",num_layers)\n",
        "print(\"Score: \",score)\n",
        "print(\"std: \",std)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.452 (std: 0.031)\n",
            "Parameters: {'module__num_layers': 4, 'module__hidden_size': 50, 'max_epochs': 100, 'batch_size': 150}\n",
            "\n",
            "2\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.308 (std: 0.047)\n",
            "Parameters: {'module__num_layers': 2, 'module__hidden_size': 80, 'max_epochs': 100, 'batch_size': 700}\n",
            "\n",
            "Batch size:  [150, 700]\n",
            "Hidden Dim:  [50, 80]\n",
            "Max epochs:  [100, 100]\n",
            "Num layers:  [4, 2]\n",
            "Score:  [0.4518280946719958, 0.3077473223779089]\n",
            "std:  [0.03140069462713873, 0.04719964138238955]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slhLlr6ekwBG",
        "colab_type": "code",
        "outputId": "c54e8007-23e0-47fb-baba-c936e7f50c08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "source": [
        "hidden_dim = hidden_size\n",
        "ejex = hidden_dim\n",
        "ejey = num_layers\n",
        "ejez = score\n",
        "\n",
        "plotx,ploty, = np.meshgrid(np.linspace(np.min(ejex),np.max(ejex),10),\\\n",
        "                           np.linspace(np.min(ejey),np.max(ejey),10))\n",
        "plotz = interp.griddata((ejex,ejey),ejez,(plotx,ploty),method='cubic')\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.view_init(35,40)\n",
        "ax.set_xlabel('Neuronas')\n",
        "ax.set_ylabel('Capas')\n",
        "ax.set_zlabel('Precisión')\n",
        "ax.set_title('Precisión en función de la arquitectura')\n",
        "\n",
        "surf = ax.plot_surface(plotx,ploty,plotz,vmin=np.nanmin(ejez),vmax = np.nanmax(ejez),cstride=1,rstride=1,cmap='viridis')\n",
        "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
        "plt.savefig(\"prueba4_Neuronas_Capas_Precision.svg\")\n",
        "#/////////////////////////////\n",
        "#////////////////////////////\n",
        "\n",
        "ejex = hidden_dim\n",
        "ejey = num_layers\n",
        "ejez = std\n",
        "\n",
        "plotx,ploty, = np.meshgrid(np.linspace(np.min(ejex),np.max(ejex),10),\\\n",
        "                           np.linspace(np.min(ejey),np.max(ejey),10))\n",
        "plotz = interp.griddata((ejex,ejey),ejez,(plotx,ploty),method='cubic')\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.view_init(35,40)\n",
        "ax.set_xlabel('Neuronas')\n",
        "ax.set_ylabel('Capas')\n",
        "ax.set_zlabel('Std')\n",
        "ax.set_title('Std en función de la arquitectura')\n",
        "\n",
        "surf = ax.plot_surface(plotx,ploty,plotz,vmin=np.nanmin(ejez),vmax = np.nanmax(ejez),cstride=1,rstride=1,cmap='viridis')\n",
        "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
        "plt.savefig(\"prueba4_Neuronas_Capas_STD.svg\")\n",
        "#/////////////////////////////\n",
        "#////////////////////////////\n",
        "\n",
        "ejex = max_epochs\n",
        "ejey = batch_size\n",
        "ejez = score\n",
        "\n",
        "plotx,ploty, = np.meshgrid(np.linspace(np.min(ejex),np.max(ejex),10),\\\n",
        "                           np.linspace(np.min(ejey),np.max(ejey),10))\n",
        "plotz = interp.griddata((ejex,ejey),ejez,(plotx,ploty),method='cubic')\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.view_init(35,120)\n",
        "ax.set_xlabel('Epocas')\n",
        "ax.set_ylabel('Batch')\n",
        "ax.set_zlabel('Precisión')\n",
        "ax.set_title('Precisión en función de tamaño de batch y épocas')\n",
        "\n",
        "surf = ax.plot_surface(plotx,ploty,plotz,vmin=np.nanmin(ejez),vmax = np.nanmax(ejez),cstride=1,rstride=1,cmap='viridis')\n",
        "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
        "plt.savefig(\"prueba4_Epocas_Batch_Precision.svg\")\n",
        "\n",
        "#/////////////////////////////\n",
        "#////////////////////////////\n",
        "\n",
        "ejex = max_epochs\n",
        "ejey = batch_size\n",
        "ejez = std\n",
        "\n",
        "plotx,ploty, = np.meshgrid(np.linspace(np.min(ejex),np.max(ejex),10),\\\n",
        "                           np.linspace(np.min(ejey),np.max(ejey),10))\n",
        "plotz = interp.griddata((ejex,ejey),ejez,(plotx,ploty),method='cubic')\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.view_init(35,120)\n",
        "ax.set_xlabel('Epocas')\n",
        "ax.set_ylabel('Batch')\n",
        "ax.set_zlabel('Std')\n",
        "ax.set_title('Std en función de tamaño de batch y épocas')\n",
        "\n",
        "surf = ax.plot_surface(plotx,ploty,plotz,vmin=np.nanmin(ejez),vmax = np.nanmax(ejez),cstride=1,rstride=1,cmap='viridis')\n",
        "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
        "plt.savefig(\"prueba4_Epocas_Batch_STD.svg\")\n",
        "\n",
        "#/////////////////////////////\n",
        "#////////////////////////////\n",
        "\n",
        "ejex = hidden_dim\n",
        "ejey = max_epochs\n",
        "ejez = score\n",
        "\n",
        "plotx,ploty, = np.meshgrid(np.linspace(np.min(ejex),np.max(ejex),10),\\\n",
        "                           np.linspace(np.min(ejey),np.max(ejey),10))\n",
        "plotz = interp.griddata((ejex,ejey),ejez,(plotx,ploty),method='cubic')\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.view_init(35,120)\n",
        "ax.set_xlabel('Neuronas')\n",
        "ax.set_ylabel('Epocas')\n",
        "ax.set_zlabel('Precisión')\n",
        "ax.set_title('Precisión en función de neuronas y épocas')\n",
        "\n",
        "surf = ax.plot_surface(plotx,ploty,plotz,vmin=np.nanmin(ejez),vmax = np.nanmax(ejez),cstride=1,rstride=1,cmap='viridis')\n",
        "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
        "plt.savefig(\"prueba4_Neuronas_Epocas_Precision.svg\")\n",
        "\n",
        "#print(X_test.shape)            \n",
        "probs = gs.best_estimator_.predict_proba(X_test)\n",
        "#print(probs.shape)\n",
        "\n",
        "# get training and validation loss\n",
        "epochs = [i for i in range(len(gs.best_estimator_.history))]\n",
        "train_loss = gs.best_estimator_.history[:,'train_loss']\n",
        "valid_loss = gs.best_estimator_.history[:,'valid_loss']\n",
        "acc = balanced_accuracy_score(y_test_tensor,np.argmax(probs,axis=1))\n",
        "print(\"tasa de acierto obtenida: \",acc)\n",
        "fig1 = plt.figure()\n",
        "plt.plot(epochs,train_loss,'g-')\n",
        "plt.plot(epochs,valid_loss,'r-')\n",
        "plt.title('Curvas del error en el entrenamiento')\n",
        "plt.xlabel('Epocas')\n",
        "plt.ylabel('Error (Cross Entropy Loss)')\n",
        "plt.legend(['Entrenamiento','Validación'])\n",
        "plt.savefig(\"prueba4_Loss.svg\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "QhullError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mQhullError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-267405d36d84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplotx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mploty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mejex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mejex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                           \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mejey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mejey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplotz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgriddata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mejex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mejey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mejez\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplotx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mploty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cubic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'3d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/interpolate/ndgriddata.py\u001b[0m in \u001b[0;36mgriddata\u001b[0;34m(points, values, xi, method, fill_value, rescale)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cubic'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         ip = CloughTocher2DInterpolator(points, values, fill_value=fill_value,\n\u001b[0;32m--> 226\u001b[0;31m                                         rescale=rescale)\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32minterpnd.pyx\u001b[0m in \u001b[0;36mscipy.interpolate.interpnd.CloughTocher2DInterpolator.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mqhull.pyx\u001b[0m in \u001b[0;36mscipy.spatial.qhull.Delaunay.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mqhull.pyx\u001b[0m in \u001b[0;36mscipy.spatial.qhull._Qhull.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mQhullError\u001b[0m: QH6214 qhull input error: not enough points(2) to construct initial simplex (need 4)\n\nWhile executing:  | qhull d Qz Qc Qt Q12 Qbb\nOptions selected for Qhull 2015.2.r 2016/01/18:\n  run-id 2006973061  delaunay  Qz-infinity-point  Qcoplanar-keep  Qtriangulate\n  Q12-no-wide-dup  Qbbound-last  _pre-merge  _zero-centrum  Qinterior-keep\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTVQ0-7wZMRR",
        "colab_type": "code",
        "outputId": "9643b4a8-3c47-4367-8217-e578682d29e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "acc = balanced_accuracy_score(y_test_tensor,np.argmax(probs,axis=1))\n",
        "print(\"tasa de acierto obtenida: \",acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tasa de acierto obtenida:  0.5440251572327044\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}